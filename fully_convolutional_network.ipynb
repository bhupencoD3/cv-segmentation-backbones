{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8788fb09",
   "metadata": {},
   "source": [
    "#### Fully Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd14ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "674de295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as model\n",
    "vgg=model.vgg16(weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73648b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "734772fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.78\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 747.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vgg,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "570aba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9baf8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN8(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(FCN8,self).__init__()\n",
    "        vgg = model.vgg16(weights=True)\n",
    "\n",
    "        self.features=vgg.features ## till convolutional and pooling\n",
    "\n",
    "        self.pool3=self.features[:17]\n",
    "        self.pool4=self.features[:24]\n",
    "        self.pool5=self.features\n",
    "\n",
    "        # 1x1 convolutions to convert to class scores\n",
    "        self.conv1x1_3=nn.Conv2d(256,num_classes,kernel_size=1)\n",
    "        self.conv1x1_4=nn.Conv2d(512,num_classes,kernel_size=1)\n",
    "        self.conv1x1_5=nn.Conv2d(512,num_classes,kernel_size=1)  \n",
    "\n",
    "        self.upsample32 = nn.ConvTranspose2d(num_classes,num_classes,kernel_size=4,stride=2,padding=1)\n",
    "        self.upsample16 = nn.ConvTranspose2d(num_classes,num_classes,kernel_size=4,stride=2,padding=1)\n",
    "        self.upsample8 = nn.ConvTranspose2d(num_classes,num_classes,kernel_size=16,stride=8,padding=4)\n",
    "\n",
    "    def forward(self,x):\n",
    "        pool3_out = self.pool3(x)\n",
    "        pool4_out = self.pool4(x)\n",
    "        pool5_out = self.pool5(x)\n",
    "\n",
    "        pool3_out = self.conv1x1_3(pool3_out)\n",
    "        pool4_out = self.conv1x1_4(pool4_out)\n",
    "        pool5_out = self.conv1x1_5(pool5_out)\n",
    "\n",
    "        x = self.upsample32(pool5_out) + pool4_out\n",
    "        x = self.upsample16(x) + pool3_out\n",
    "        x = self.upsample8(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a9a59",
   "metadata": {},
   "source": [
    "###### I = 'Input Size'\n",
    "###### S = 'Stride'\n",
    "###### K = 'Kernel Size'\n",
    "###### P = 'Padding'\n",
    "###### output = ( I - 1 ) * S + K - 2 * P\n",
    "###### input_size = 224,224 == 2\n",
    "###### max_pool5 = 7,7 == 224/7 == 32x\n",
    "###### max_pool4 = 14,14 == 224/14 == 16x\n",
    "###### max_pool13 = 28,28 == 224/28 = 8x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b10668d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape:  torch.Size([1, 1000, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "## dummy input\n",
    "model  = FCN8(num_classes=1000)\n",
    "dummy_input=torch.rand(1,3,224,224)\n",
    "output = model(dummy_input)\n",
    "print('Output Shape: ',output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
